{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#set context\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "max_iter = 20\n",
    "clusters = 10\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def split(l):\n",
    "    line=l.split(' ')\n",
    "    val = [float(s) for s in line if s is not ''] \n",
    "    return tuple(val)\n",
    "\n",
    "def combine_with_cluster(l,clu):\n",
    "    return [(l,c) for c in clu]\n",
    "\n",
    "def calc_dist(l, norm=2):\n",
    "    dist = np.linalg.norm(np.array(l[0])-np.array(l[1]),ord=norm)\n",
    "    return (l[0],(dist,l[1]))\n",
    "\n",
    "def calc_new_cluster(l):\n",
    "    l = list(l)\n",
    "    size = len(l)\n",
    "    agg = sum(np.array(l))\n",
    "    return tuple(agg/size)\n",
    "\n",
    "def get_costs(init_clusters,norm):\n",
    "    costs = []\n",
    "    curr_clusters = init_clusters\n",
    "    for i in range(max_iter): # k - means algorithm\n",
    "        combos = docs.flatMap(lambda l:combine_with_cluster(l,curr_clusters)) #get (vec,clu) pairs\n",
    "        combos_w_euc_dist = combos.map(lambda l:calc_dist(l,norm)) #add the distance to said cluster\n",
    "        combos_w_euc_dist_grouped = combos_w_euc_dist.groupByKey()\n",
    "        closest = combos_w_euc_dist_grouped.mapValues(lambda val: min(list(val))) # filter such that only the closest (dist,clust) remains as value for a vector\n",
    "        costs += [sum(closest.map(lambda l:l[1][0]).collect())] #add costs for this clustering\n",
    "        curr_clusters = closest.map(lambda l : (l[1][1],l[0])).groupByKey() #sort all vectors to its cluster\n",
    "        new_clusters = curr_clusters.map(lambda l: calc_new_cluster(l[1])) #calculate new clusters\n",
    "        curr_clusters = new_clusters.collect()\n",
    "        print('Current cost is', costs[-1])\n",
    "    return costs\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#read file in\n",
    "docs = sc.textFile('./data/data.txt').map(split)\n",
    "c1 = sc.textFile('./data/c1.txt').map(split)\n",
    "c2 = sc.textFile('./data/c2.txt').map(split)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "cluster_rand = c1.collect()\n",
    "cluster_max = c2.collect()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "costs_rand = get_costs(cluster_rand,2)\n",
    "\n",
    "costs_max = get_costs(cluster_max,2)\n",
    "\n",
    "# costs_max = []\n",
    "# curr_clusters = cluster_max\n",
    "# for i in range(max_iter): # k - means algorithm\n",
    "#     combos = docs.flatMap(lambda l:combine_with_cluster(l,curr_clusters)) #get (vec,clu) pairs\n",
    "#     combos_w_euc_dist = combos.map(lambda l:calc_dist(l,None)) #add the distance to said cluster\n",
    "#     combos_w_euc_dist_grouped = combos_w_euc_dist.groupByKey()\n",
    "#     closest = combos_w_euc_dist_grouped.mapValues(lambda val: min(list(val))) # filter such that only the closest (dist,clust) remains as value for a vector\n",
    "#     costs_max += [sum(closest.map(lambda l:l[1][0]).collect())] #add costs for this clustering\n",
    "#     curr_clusters = closest.map(lambda l : (l[1][1],l[0])).groupByKey() #sort all vectors to its cluster\n",
    "#     new_clusters = curr_clusters.map(lambda l: calc_new_cluster(l[1])) #calculate new clusters\n",
    "#     curr_clusters = new_clusters.collect()\n",
    "#     print('Current cost is', costs_max[-1])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.plot(costs_rand, label = 'Random')\n",
    "plt.plot(costs_max, label= 'Max Dist')\n",
    "plt.legend()\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iteration No.')\n",
    "plt.title('Cost of k-mean algo using euclidean distance')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "costs_rand_man = get_costs(cluster_rand,1)\n",
    "costs_max_man = get_costs(cluster_max,1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.plot(costs_rand_man, label = 'Random')\n",
    "plt.plot(costs_max_man, label= 'Max Dist')\n",
    "plt.legend()\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iteration No.')\n",
    "plt.title('Cost of k-mean algo using manhattan distance')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "a = sc.parallelize([(\"a\",(0,(2,2))), (\"b\",(0,(3,6))), (\"c\",(3,(5,2))), (\"d\",(4,(3,1))),(\"d\",(2,(3,9))),(\"a\",(1,(3,3)))]).groupByKey()\n",
    "def test(val):\n",
    "    return min(val)\n",
    "maxKey = a.mapValues(lambda val: min(list(val)))\n",
    "maxKey.collect()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "a = (3,2)\n",
    "b = (3,1)\n",
    "sum(np.array([a,b]))/len([a,b])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
